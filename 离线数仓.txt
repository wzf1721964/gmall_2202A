各位面试官好，我叫段鎏雨，首先呢非常荣幸能够参加本次的面试，我先介绍一下我的工作经历，20年毕业之后就入职了深圳亿腾公司，一直到现在为止有四年的时间，在这四年里离线项目和实时项目我都有做过，主要工作内容得话有数据采集，数据优化，数仓0到1的搭建，数仓分析，数据建模，熟通Hadoop、Hive、Spark、Flink等主流大数据技术，以及使用bi工具去做数据的可视化展示，如finebi，永洪bi，java方面的话我主要就是负责写一些后端的接口，还可以做一些python方面的开发以及算法的使用。平时工作内容的话除了写写sql做一下指标开发外，还做过数仓建模，数仓的优化，元数据的管理。（电子商务、金融借贷项目）
项目介绍
	最近做过的一个项目是电商数仓项目，首先是数据采集方面，我们主要使用dataX来采集全量数据，用 	flume、kafka、Maxwell来采集增量数据，然后使用hdfs来储存数据，数仓的搭建我们使用的是hive,我们数仓的分层也	和市	面上的数仓分层基本相似分为:ods、dwd、dws、dim、ads五个层面，我们的ODS层(原始数据层，贴源层)存储的	是不做处理的原始数据，然后DWD层是基于维度建模理论进行构建主要就是对ODS层的数据做一些清洗、脱敏，DIM层	（基于维度建模理论）存放维度模型中的维度表，保存一致性维度信息、DWS层基于ADS层的指标需求，以分析的主题	对象为建模驱动，对数据进行一些简单的汇总、ADS层主要就是计算并存放各项统计指标结果，最后我们将ads层的指标	使用FIneBI进行可视化展示，来给公司产品的决策制定提供数据支撑
（郭院，您好，~   我们本周做的项目是~）
讲背景
	在电商蓬勃发展的当下，数据量呈爆炸式增长。公司需要整合分散在各处的海量数据，以更好地了解消费者需求、优化运	营策略。电商数仓通过对电商数据的采集、存储和分析，实现对数据的有效利用，为公司产品的运营提供强有力的数据支	撑，可以让领导直观的看到商品的销售情况和用户的购买情况，以便给公司产品做出更好的营销策略
讲需求
	我们这个项目数据来源分为两部分，业务数据（存储在Mysql数据库中），用户行为数据我们通过flume采集存放在日	志文件中，通过用户行为数据和业务数据分析，做了一些相对应的指标来帮助我们更好的分析每日用户的访客量、流失情	况，以及商品的收藏购买情况。
讲实现
	我们的数据主要有两块，第一块的话就是前端的埋点数据，第二块就是我们的业务数据，
	前端的埋点数据我们通过flume进行监控采集到kafka对数据进行缓存处理，再通过flume采集kafka数据到hdfs的指定路	径中
	业务数据我们是由全量数据和增量数据两部分组成，全量数据我们是使用的dataX将数据同步道hdfs中，全量数据我们是	使用maxwell+kafka将业务数据中的新增和数据变化同步道hdfs中，
	然后将hdfs中的所有数据拉取到hive中进行数仓搭建，最后对数据进行分析和计算求出所需指标，并使用BI工具对指标进	行可视化展示
讲难点
	flume零点漂移问题
	hive数据倾斜
	维度层用户拉链表
讲解决
	flume零点漂移问题
		将日志中记录的日志创建时间提取出来，写入flume事件头的timestamp字段，有了这个字段flume创建文件时，		会根据这个字段创建文件
	hive数据倾斜
		数据分布不均匀
			在进行join或者group by之前对数据采样，找出数据量较大的键值进行特殊处理
		大小表关联时产生的数据倾斜
			1.小表在前
			2.使用mapjoin将小表缓存到内存中，在map端将小表和大表进行关联，从而省去reduce端的操作，不会产			生shuffle
		不同数据类型关联产生的数据倾斜
			关联字段数据类型转换一致
		不合理的分区策略
			使用动态分区
		建表的时候使用orc格式
	维度层用户拉链表  
		用户维度表数据量大但是频繁变化小属于缓慢变化维度数据 解决缓慢变化维数据，通过生效开始日期<=某个日期		且生效结束日期>=某个日期，能够得到某个时间点的数据全量切片

讲拓展
	Datex和Sqoop都是数据迁移和集成的常用工具
		sqoop支持关系型数据库批量导入到hadoop以及从hadoop批量导出，通过多个map任务并行处理数据提高数据			迁移的效率，可以确保数据传输的安全性，用户还可以通过配置文件或者命令行参数来定制数据迁移行为(指			定列、过滤条件)
		DateX支持多种数据源（关系型数据库、NoSQL数据库、日志文件等）可以对特定业务场景进行定制，可以包含特			定的数据转换和数据处理逻辑，在处理大规模数据时优化了数据迁移的性能，在数据迁移过程中提供数据质			量检查(确保数据的完整性和准确性)和任务的调度、监控功能(便于管理和维护)
		如果需要一个通用且成熟的工具sqoop是不错的选择，如果业务场景复杂，需要高度定制化的数据迁移和处理逻			辑，DateX可能更合适

讲优化
	hive表优化
		数据分区、分桶、压缩、存储格式优化
	hiveSQL优化
		小表关联大表的join优化
		使用缓存表（对于频繁访问的小表，可以将其缓存到内存中来提高查询性能）
		使用谓词下推(将过滤条件尽可能早的使用，减少中间数据的产生)
讲双新
	Azkaban和Dolphin（DS）
		Azkaban：
			本身他是不支持高可用HA，需要HA额外要求，任务太多的时候会卡死，DAG监控页面只能看到任务状态，		不支持可视化流程定义，需要自定义DSL绘制DAG并打包上传，集群化部署复杂，不支持暂停和恢复，要暂定就要		先将工作流杀死再重新运行，不支持多租户，
		在大数据平台业务使用不够灵活。
		Dolphin（DS）：
			本身就支持高可用HA，所以不需要额外的HA要求， 任务队列机制，单个机器上可调度的任务数量可以灵活		配置，任务过多时会缓存在任务队列中，不会造成机器卡死，任务状态、任务类型、重试次数、任务运行机器、可		视化变量等关键信息一目了然，所有流程定义操作都是可视化的，通过拖拽任务来实现DAG，配置数据源及资源，		对于第三方系统，提供api方式的操作，一键快速部署，支持暂停、恢复操作，支持多租户，支持大数据作业			spark、hive、mr的调度，与大数据业务更加契合

	DataX和Sqoop
		DataX：
			单进程多线程的运行模式，单击读写mysql压力大，读写粒度容易控制，hive读写压力大，支持orc的文件格		式，日志相比于sqoop比较完善和人性化
		Sqoop：
			采用了map-reduce的计算框架，能够在多个节点上并行执行任务的导入和导出，具备更高的性能，相比之下		dataX在单台机器上进行数据提取和加载，性能受限。在某些情况下，dataX性能比sqoop好，取决于具体的数据		源、目标存储、网格环境的因素，分布式同步，数据量小的情况下考虑这个，数据基于yarn不容易采集

